{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WTlAfoEarw32"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from io import BytesIO\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PalmDataset(Dataset):\n",
        "    def __init__(self, csv_file, zip_file, transform=None):\n",
        "        self.labels = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.zip_file = zip_file\n",
        "\n",
        "        # Открываем ZIP-файл\n",
        "        self.archive = zipfile.ZipFile(zip_file, 'r')\n",
        "\n",
        "        # Фильтрация данных только для ладоней\n",
        "        self.labels = self.labels[self.labels['aspectOfHand'].str.contains('palmar', case=False, na=False)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Получаем имя изображения\n",
        "        img_name = self.labels.iloc[idx, 7]  # imageName\n",
        "        img_path = f\"Hands/{img_name}\"  # Путь к файлу внутри архива, если все изображения в папке \"images\"\n",
        "\n",
        "        # Извлекаем изображение из архива\n",
        "        with self.archive.open(img_path) as img_file:\n",
        "            img = Image.open(BytesIO(img_file.read())).convert(\"RGB\")\n",
        "\n",
        "        # Применяем трансформации, если они заданы\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # Получаем метки\n",
        "        age = self.labels.iloc[idx, 1]  # возраст\n",
        "        skin_color = self.labels.iloc[idx, 3].lower()  # цвет кожи\n",
        "        accessories = self.labels.iloc[idx, 4]  # наличие аксессуаров\n",
        "\n",
        "        skin_color_mapping = {'very fair': 0,'fair': 1, 'medium': 2, 'dark': 3} #['fair' 'dark' 'medium' 'very fair']\n",
        "        skin_color_label = skin_color_mapping.get(skin_color, -1)\n",
        "\n",
        "        # Преобразование меток в числовой формат (например, one-hot)\n",
        "        label = torch.tensor([age, skin_color_label, accessories], dtype=torch.float32)\n",
        "\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "hdjMe34MsMFZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь к CSV файлу с метками и путь к ZIP-файлу с изображениями\n",
        "csv_file = '/content/dataset/HandInfo.csv'\n",
        "zip_file = '/content/dataset/images/Hands.zip'\n",
        "\n",
        "# Определяем преобразования для изображений\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),  # Изменение размера изображения до 512x512\n",
        "    transforms.ToTensor(),  # Преобразование изображения в тензор\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Нормализация\n",
        "])\n",
        "\n",
        "# Создаем датасет с использованием класса PalmDataset\n",
        "dataset = PalmDataset(csv_file=csv_file, zip_file=zip_file, transform=transform)\n",
        "\n",
        "# Создаем DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "LfSf9bNS4JpP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConditionalGenerator(nn.Module):\n",
        "    def __init__(self, latent_dim, condition_dim):\n",
        "        super(ConditionalGenerator, self).__init__()\n",
        "\n",
        "        # Генератор принимает на вход шумовой вектор + вектор признаков\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(latent_dim + condition_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512 * 512 * 3),\n",
        "            nn.Tanh()  # Изображения от -1 до 1\n",
        "        )\n",
        "\n",
        "    def forward(self, z, condition):\n",
        "        x = torch.cat([z, condition], dim=1)  # Объединение шума и признаков\n",
        "        img = self.fc(x)\n",
        "        img = img.view(-1, 3, 512, 512)  # Преобразование в изображение\n",
        "        return img"
      ],
      "metadata": {
        "id": "aq4u6Y4-6RSC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(512 * 512 * 3, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Sigmoid()  # Выходное значение - вероятность того, что изображение реальное\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)  # Преобразование в одномерный вектор\n",
        "        validity = self.model(img_flat)\n",
        "        return validity\n"
      ],
      "metadata": {
        "id": "n-y4udEr6fyn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение устройства (GPU или CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Параметры GAN\n",
        "latent_dim = 100  # Размер шумового вектора\n",
        "condition_dim = 3  # Возраст, цвет кожи, аксессуары\n",
        "lr = 0.0002\n",
        "num_epochs = 100\n",
        "\n",
        "# Инициализация модели\n",
        "generator = ConditionalGenerator(latent_dim, condition_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Оптимизаторы\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "\n",
        "# Функция потерь\n",
        "adversarial_loss = nn.BCELoss()\n",
        "\n",
        "# Тренировочный цикл\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (real_imgs, labels) in enumerate(dataloader):\n",
        "\n",
        "        # Метки для настоящих и фейковых изображений\n",
        "        valid = torch.ones(real_imgs.size(0), 1).to(device)\n",
        "        fake = torch.zeros(real_imgs.size(0), 1).to(device)\n",
        "\n",
        "        # Настоящие изображения\n",
        "        real_imgs = real_imgs.to(device)\n",
        "        labels = labels.to(device)  # Метки: возраст, цвет кожи, аксессуары\n",
        "\n",
        "        # === Тренировка дискриминатора ===\n",
        "\n",
        "        # Генерация шума и фейковых изображений\n",
        "        z = torch.randn(real_imgs.size(0), latent_dim).to(device)\n",
        "        gen_imgs = generator(z, labels)\n",
        "\n",
        "        # Рассчитываем потери дискриминатора на реальных и фейковых изображениях\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        # Обновляем дискриминатор\n",
        "        optimizer_D.zero_grad()\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # === Тренировка генератора ===\n",
        "\n",
        "        # Теперь дискриминатор оценивает фейковые изображения как \"настоящие\"\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "\n",
        "        # Обновляем генератор\n",
        "        optimizer_G.zero_grad()\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    print(f\"Epoch {epoch}/{num_epochs} | D loss: {d_loss.item()} | G loss: {g_loss.item()}\")\n"
      ],
      "metadata": {
        "id": "tjWdAMK_6kVl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}